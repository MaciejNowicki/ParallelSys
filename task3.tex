1. 
Scheduler is a part of Operating System that determines when to change actually executed process/thread and which of the processes/threads in ready state should be exequted next. In order to do that scheduler use scheduling algorithm which is designed depending on purpose of the system, its requirements and application.
2.
States:
Running - number (index) of currently running thread is stored in cpu_private_data.thread_index
Ready - indexes of all threads in ready state are placed in ready_queue - instance of thread_queue structure.
Blocked - Due to the fact, that in our design only way to make thread blocked is invocation of function pause(), indexes of all blocked (paused) threads are stored in timer queue.
Transitions:
From ready to running:
Nonpreemptive - When process of currently running thread is terminated, scheduler_called_from_system_call_handler is called with argument 'scheduler' equal 1 and finally thread of index stored in ready_queue.head is dequeued and placed in cpu_private_data.thread_index.
Preemptive and Priority - In addition to solution for nonpreemptive scheduler, at each timer interrupt (occuring with frequency of 100Hz) scheduler_called_from_timmer_interrupt_handler is called and if running thread was not set in timer_interrupt_handler and cpu_private_data.ticks_left_of_time_slice is equal 0, thread of index stored in ready_queue.head is dequeued and placed in cpu_private_data.thread_index.
From running to ready:
Nonpreemptive - n/a
Preemptive and Priority - Before ready_queue.head is dequeued and placed in cpu_private_data.thread_index in order to change its state from ready to running, index of thread stored in cpu_private_data.thread_index is enqueued into ready_queue. We can say, that in our design transitions from running to ready state is interrelated and inseparable from transition in oposite direction.
From running to blocked:
This transition is done by calling function pause(), what results in placing thread in timer queue.
From blocked to running:
In our design this transition is possible only in one case - when all threads are in blocked state (cpu_private_data.thread_index is equal to -1) and number of timer ticks to wait stored in thread_table[timer_queue_head].data.list_data is smaller or equal to zero, thread of index stored in timer_queue_head is directly placed in cpu_private_data.thread_index
From blocked to ready:
In the case similar to presented in the section concerning transition from blocked to running state, but when some thread is running (cpu_private_data.thread_index is not equal to -1), all threads in timer queue having number of timer ticks to wait smaller or equal to zero ale enqueued into ready_queue.
3.
Nonpreemptive and Preemptive:
Thread queue is FIFO, Singly linked list that uses two structures: thread_queue and thread. Ready_queue, instance of thread_queue, contains indexes of threads in thread_table (of type thread[]), that are head and tail of the list. Thread structure represents node - it contains index of next node (next thread in thread queue) and some relevant data. When new element is enqueued it is placed as tail of ready_queue, but dequeue results in removing head of the list.
Priority:
In order to obtain priority scheduler we added to design for task B3 2 new members of thread structure: data.main_priority containing priority of the thread and data.priority that is actual priority of the thread. Then we changed way of enqueuing and dequeuing threads and in the result threads are sorted in such a way, that thread with highest data.priority value is head of thread queue and one with smallest data.priority is the tail. It means, that thread queue is no longer FIFO. 
When time slice of currently executed thread is equal to zero its data.priority is decremented and the thread is enqueued. Then if all threads in queue have data.priority equal to zero, their priorities are restored from data.main_priority and thread queue is sorted (using bubblesort due to complexity of thread queue). Finally, as usually, index of the head is placed in cpu_private_data.thread_index.
4.Timer queue is used to store paused threads. It is Singly linked list that uses thread structure and the timer_queue_head variable. It works in following way: timer_queue_head stores index of thread that as the first one will change its state from blocked to ready (or running). Thread_table[timer_queue_head].data.list_data contains number of timer ticks to wait and the data.next stores index of paused thread (or -1 if there is no more paused threads), that will modify its state as the next one. In the case of following threads in timer queue, data.next has the same meanning, but data.list_data contains number of timer ticks to wait after change of state of previous one - thanks that, CPU has to decrement maximally one counter at each timer tick (in timer_interrup_handle()) instead of decrementing counters of each thread in timer queue. When data.list_data of thread of index equal to timer_queue_head is equal 0, all threads in timer queue having data.list_data equal 0 (there may be a few threads paused for the same ammount of time) change their state to ready and index of first thread in timer queue having data.list_data > 0 becomes new timer_queue_head (or it is set to -1 if there is no more paused threads).
5.
In nonpreemptive scheduler, scheduling decision is made only if currently running thread is finished or if it decides to give another thread chance to be executed. Preepmtive scheduler provides making scheduling decision at some time intervals, that results in implementing timer interrupt handler calling scheduler that switches states of two threads - for one of them from running to ready and oppositely for the second one.
6.
Operating system supporting processes with real-time requirements must be equiped with tools helping it to meet the requirements. Best possible solution is such, that OS knows exact time requirements of each process and is able to schedule them avoiding as much as possible data loss. If it is impossible, processes schould be prioritized in such a way, that these with real-time requirements are more important and takes more CPU utilization time than other processes.
7.
Type of scheduling algorithm influances only part of kernel data structures connected with scheduling, all other parts remain the same. Generally more effective and less time consuming algorithm gives more complex data structures. For example algorithm used in latest release of Linux uses red-black tree structure that gives O(log N) time complexity. We can say, that scheduling is almost everytime connected with some queue, so to create the queue we should use data structure that has as small as possible time complexity of insertion, deletion and sorting elements - then only algorithm to calculate importance of certain element may be main source of time complexity.
In order to obtain scheduler's time complexity of O(1) in Linux Kernel 2.6, 2 runqueue structures were used: active containing threads that are waiting for execution and expired one containing threads that used all of its time slice (but their time slice is recalculated during move to expired runqueue!). When all threads in active are moved to expired runqueue, pointers to runqueues are swapped - expired becomes active and vice versa. Another important thing is that bitwise operations are used in order to determine which thread has the highest priority.

